{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:12:45.725275Z",
     "iopub.status.busy": "2025-04-07T15:12:45.724808Z",
     "iopub.status.idle": "2025-04-07T15:12:52.652038Z",
     "shell.execute_reply": "2025-04-07T15:12:52.650785Z",
     "shell.execute_reply.started": "2025-04-07T15:12:45.725207Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python-headless pandas numpy pillow requests python-docx matplotlib tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:19:59.481619Z",
     "iopub.status.busy": "2025-04-07T17:19:59.481375Z",
     "iopub.status.idle": "2025-04-07T17:20:22.161694Z",
     "shell.execute_reply": "2025-04-07T17:20:22.160615Z",
     "shell.execute_reply.started": "2025-04-07T17:19:59.481598Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.5\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, click, jiwer\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "Successfully installed click-8.1.8 jiwer-3.1.0 rapidfuzz-3.13.0\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 129 not upgraded.\n",
      "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "!pip install python-docx\n",
    "!pip install jiwer\n",
    "!apt-get install -y tesseract-ocr\n",
    "!pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:22:43.165323Z",
     "iopub.status.busy": "2025-04-07T17:22:43.164962Z",
     "iopub.status.idle": "2025-04-07T17:23:00.344152Z",
     "shell.execute_reply": "2025-04-07T17:23:00.343565Z",
     "shell.execute_reply.started": "2025-04-07T17:22:43.165296Z"
    },
    "id": "N9RkEbNF6Y2h",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import fitz\n",
    "import cv2\n",
    "from docx import Document\n",
    "import string\n",
    "import requests\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow.data as tfd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:23:03.952315Z",
     "iopub.status.busy": "2025-04-07T17:23:03.951738Z",
     "iopub.status.idle": "2025-04-07T17:23:04.083198Z",
     "shell.execute_reply": "2025-04-07T17:23:04.082099Z",
     "shell.execute_reply.started": "2025-04-07T17:23:03.952283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rm -rf /kaggle/working/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting individual pages from the source pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:23:08.837938Z",
     "iopub.status.busy": "2025-04-07T17:23:08.837620Z",
     "iopub.status.idle": "2025-04-07T17:23:10.443013Z",
     "shell.execute_reply": "2025-04-07T17:23:10.442330Z",
     "shell.execute_reply.started": "2025-04-07T17:23:08.837914Z"
    },
    "id": "F-6-ptAESBHd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_images_from_pdf(pdf_path, output_folder):\n",
    "    pdf_doc = fitz.open(pdf_path)\n",
    "    totalpages=len(pdf_doc)\n",
    "    for page_num in range(totalpages):\n",
    "        page = pdf_doc.load_page(page_num)\n",
    "        pixmap = page.get_pixmap()\n",
    "        image_path = os.path.join(output_folder, f'page_{page_num + 1}.png')\n",
    "        pixmap.save(image_path)\n",
    "\n",
    "    pdf_doc.close()\n",
    "\n",
    "pdf = \"/kaggle/input/pdf-buendia/Buendia - Instruccion.pdf\"  # PDF\n",
    "images_folder = \"/kaggle/working/imgs_pdf1\"  # Output folder to save images\n",
    "if not os.path.exists(images_folder):\n",
    "    os.makedirs(images_folder)\n",
    "get_images_from_pdf(pdf, images_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting each page vertically\n",
    "### This is because the pdf used for text recognition here has 2 pages side by side in one image.In general we can decide whether to split or not based on the image width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:23:12.287483Z",
     "iopub.status.busy": "2025-04-07T17:23:12.287142Z",
     "iopub.status.idle": "2025-04-07T17:23:13.907392Z",
     "shell.execute_reply": "2025-04-07T17:23:13.906637Z",
     "shell.execute_reply.started": "2025-04-07T17:23:12.287455Z"
    },
    "id": "jWLxvNLUSD-a",
    "outputId": "eb3b7578-768c-4f0b-8646-138eac79af98",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split images saved: page_6_left.png, page_6_right.png\n",
      "Split images saved: page_2_left.png, page_2_right.png\n",
      "Split images saved: page_3_left.png, page_3_right.png\n",
      "Split images saved: page_1_left.png, page_1_right.png\n",
      "Split images saved: page_5_left.png, page_5_right.png\n",
      "Split images saved: page_4_left.png, page_4_right.png\n"
     ]
    }
   ],
   "source": [
    "def split_all_images_vertically(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = Image.open(image_path)\n",
    "            width, height = image.size\n",
    "\n",
    "            # Defining left and right halves\n",
    "            left_half = image.crop((0, 0, width // 2, height))  # Left half\n",
    "            right_half = image.crop((width // 2, 0, width, height))  # Right half\n",
    "\n",
    "            # Saving the split images\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            left_half.save(os.path.join(output_folder, f\"{base_name}_left.png\"), \"PNG\")\n",
    "            right_half.save(os.path.join(output_folder, f\"{base_name}_right.png\"), \"PNG\")\n",
    "\n",
    "            print(f\"Split images saved: {base_name}_left.png, {base_name}_right.png\")\n",
    "\n",
    "split_all_images_vertically(\"/kaggle/working/imgs_pdf1\", \"/kaggle/working/split_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:23:57.027052Z",
     "iopub.status.busy": "2025-04-07T17:23:57.026764Z",
     "iopub.status.idle": "2025-04-07T17:23:57.032768Z",
     "shell.execute_reply": "2025-04-07T17:23:57.032024Z",
     "shell.execute_reply.started": "2025-04-07T17:23:57.027032Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Paths: ['/kaggle/working/split_images/page_1_right.png', '/kaggle/working/split_images/page_2_left.png', '/kaggle/working/split_images/page_2_right.png', '/kaggle/working/split_images/page_3_left.png', '/kaggle/working/split_images/page_3_right.png', '/kaggle/working/split_images/page_4_left.png', '/kaggle/working/split_images/page_4_right.png', '/kaggle/working/split_images/page_5_left.png', '/kaggle/working/split_images/page_5_right.png', '/kaggle/working/split_images/page_6_left.png']\n"
     ]
    }
   ],
   "source": [
    "#Retrieving sorted image file paths from split_images_dir, \n",
    "# excluding the first and last images since first is blank and last is for inference\n",
    "split_images_dir = \"/kaggle/working/split_images\"\n",
    "\n",
    "all_files = sorted(os.listdir(split_images_dir))\n",
    "\n",
    "image_files = [f for f in all_files if f.endswith(\".png\")]\n",
    "\n",
    "image_paths = [os.path.join(split_images_dir, f) for f in image_files]\n",
    "\n",
    "image_paths = image_paths[1:-1]  \n",
    "\n",
    "print(\"Image Paths:\", image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training word images from all extracted pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:04.608289Z",
     "iopub.status.busy": "2025-04-07T17:25:04.607962Z",
     "iopub.status.idle": "2025-04-07T17:25:14.224731Z",
     "shell.execute_reply": "2025-04-07T17:25:14.223968Z",
     "shell.execute_reply.started": "2025-04-07T17:25:04.608266Z"
    },
    "id": "JzVmw1Ef434z",
    "outputId": "cfb09747-ce6f-4866-a129-b89308652669",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preapred an initial df with image path and corresponding labels\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Load image\n",
    "output_dir = \"./words_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "word_data = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "  image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "  gray=image\n",
    "  # Performing OCR with bounding boxes\n",
    "  custom_config = r'--oem 3 --psm 6' \n",
    "  data = pytesseract.image_to_data(gray, config=custom_config, output_type=Output.DICT)\n",
    "\n",
    "  # Processing each word\n",
    "  for i in range(len(data['text'])):\n",
    "      text = data['text'][i].strip()\n",
    "      if text:\n",
    "          x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "\n",
    "          # Extracting word image\n",
    "          word_img = image[y:y+h, x:x+w]\n",
    "\n",
    "          # Saving image with text as filename\n",
    "          word_filename = f\"{output_dir}/{text}_{i}.png\"\n",
    "          cv2.imwrite(word_filename, word_img)\n",
    "\n",
    "          # Storing file path and label in list to later add to a df\n",
    "          word_data.append((word_filename, text))\n",
    "\n",
    "          # Drawing bounding boxes on the main image\n",
    "          cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "          cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "df = pd.DataFrame(word_data, columns=[\"Image_Path\", \"Label\"])\n",
    "\n",
    "# Cleaning the df to get rid of corrupted paths\n",
    "df = df[df[\"Image_Path\"].apply(os.path.exists)]\n",
    "\n",
    "# Reseting index after filtering\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(\"word_labels.csv\", index=False)\n",
    "\n",
    "print(\"preapred an initial df with image path and corresponding labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotating the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:14.226097Z",
     "iopub.status.busy": "2025-04-07T17:25:14.225767Z",
     "iopub.status.idle": "2025-04-07T17:25:14.232205Z",
     "shell.execute_reply": "2025-04-07T17:25:14.231349Z",
     "shell.execute_reply.started": "2025-04-07T17:25:14.226070Z"
    },
    "id": "C-i5gpsYPdj_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rotation_images(df, output_dir):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    augmented_data = []  # to store (image_path, label)\n",
    "    # Iterating through the df of all extracted images\n",
    "    for _, row in df.iterrows():\n",
    "        image_path, label = row[\"Image_Path\"], row[\"Label\"]\n",
    "\n",
    "        if image_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            with Image.open(image_path) as img:\n",
    "                # Rotating images from -5 to 5 degrees to generate 10 more for each\n",
    "                for angle in range(-5, 6):\n",
    "                    if angle == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Rotating image\n",
    "                    rotated_img = img.rotate(angle, expand=True)\n",
    "\n",
    "                    # Generating new filename\n",
    "                    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                    new_filename = f\"{base_name}_rotation_by_{angle}.png\"\n",
    "                    new_path = os.path.join(output_dir, new_filename)\n",
    "\n",
    "                    # Saving rotated image\n",
    "                    rotated_img.save(new_path)\n",
    "\n",
    "                    # Storing new path & label\n",
    "                    augmented_data.append((new_path, label))\n",
    "\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:18.685938Z",
     "iopub.status.busy": "2025-04-07T17:25:18.685654Z",
     "iopub.status.idle": "2025-04-07T17:25:25.045216Z",
     "shell.execute_reply": "2025-04-07T17:25:25.044052Z",
     "shell.execute_reply.started": "2025-04-07T17:25:18.685918Z"
    },
    "id": "7bsvmLn1LzFj",
    "outputId": "bfe10c90-c2f8-4158-fc26-50c6374824e3",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added rotated images\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/kaggle/working/rotated_images\"\n",
    "rotated_list = rotation_images(df, output_dir)\n",
    "\n",
    "# Convert list to dataframe\n",
    "rotated_df = pd.DataFrame(rotated_list, columns=[\"Image_Path\", \"Label\"])\n",
    "\n",
    "rotated_df.to_csv(\"rotated_df.csv\", index=False)\n",
    "\n",
    "print(\"added rotated images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:25.047064Z",
     "iopub.status.busy": "2025-04-07T17:25:25.046799Z",
     "iopub.status.idle": "2025-04-07T17:25:25.051359Z",
     "shell.execute_reply": "2025-04-07T17:25:25.050554Z",
     "shell.execute_reply.started": "2025-04-07T17:25:25.047043Z"
    },
    "id": "qbs6KaLmTP4Q",
    "outputId": "73261ca5-69cc-4361-e2e1-bb99a8283fbf",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14530\n"
     ]
    }
   ],
   "source": [
    "print(len(rotated_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding noise to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:27.924161Z",
     "iopub.status.busy": "2025-04-07T17:25:27.923878Z",
     "iopub.status.idle": "2025-04-07T17:25:27.930530Z",
     "shell.execute_reply": "2025-04-07T17:25:27.929678Z",
     "shell.execute_reply.started": "2025-04-07T17:25:27.924139Z"
    },
    "id": "Ni3912FkUNS2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gaussian_noise(image, mean=0, var=0.01):\n",
    "    sigma = var ** 0.5  # Standard deviation\n",
    "    gauss = np.random.normal(mean, sigma, image.shape) * 255  # Scale noise\n",
    "    noisy_image = np.clip(image + gauss, 0, 255).astype(np.uint8)  # Add noise & clip\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "def augment_with_noise(df, output_dir, mean=0, var=0.01):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    augmented_data_noise = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        image_path, label = row[\"Image_Path\"], row[\"Label\"]\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Skipping missing file: {image_path}\")\n",
    "            continue \n",
    "\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Skipping unreadable file: {image_path}\")\n",
    "            continue  # Skipping corrupt images\n",
    "\n",
    "        # Gaussian noise\n",
    "        noisy_image = gaussian_noise(image, mean, var)\n",
    "\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        new_filename = f\"{base_name}_with_noise.png\"\n",
    "        new_path = os.path.join(output_dir, new_filename)\n",
    "        cv2.imwrite(new_path, noisy_image)\n",
    "\n",
    "        # Storing new path & label in a list to later add it to a dataframe\n",
    "        augmented_data_noise.append((new_path, label))\n",
    "\n",
    "    return augmented_data_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:30.063668Z",
     "iopub.status.busy": "2025-04-07T17:25:30.063322Z",
     "iopub.status.idle": "2025-04-07T17:25:30.758650Z",
     "shell.execute_reply": "2025-04-07T17:25:30.757718Z",
     "shell.execute_reply.started": "2025-04-07T17:25:30.063638Z"
    },
    "id": "JrWmeRPkUQC5",
    "outputId": "ca7312a2-a989-4ed4-e66f-3f49c8990805",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian noise images added.\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/kaggle/working/noisy_images\"\n",
    "augmented_list = augment_with_noise(df, output_dir)\n",
    "\n",
    "# Converting list to datafrane\n",
    "augmented_df_noise = pd.DataFrame(augmented_list, columns=[\"Image_Path\", \"Label\"])\n",
    "augmented_df_noise.to_csv(\"noisy_labels.csv\", index=False)\n",
    "\n",
    "print(\"Gaussian noise images added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:30.760056Z",
     "iopub.status.busy": "2025-04-07T17:25:30.759808Z",
     "iopub.status.idle": "2025-04-07T17:25:30.764270Z",
     "shell.execute_reply": "2025-04-07T17:25:30.763478Z",
     "shell.execute_reply.started": "2025-04-07T17:25:30.760034Z"
    },
    "id": "VBBbk1u-UgqV",
    "outputId": "d7c73169-22bb-4f76-89f7-c04226e9bd03",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    }
   ],
   "source": [
    "print(len(augmented_df_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening code ( can be uncommented and used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:32.465032Z",
     "iopub.status.busy": "2025-04-07T17:25:32.464723Z",
     "iopub.status.idle": "2025-04-07T17:25:32.468771Z",
     "shell.execute_reply": "2025-04-07T17:25:32.467910Z",
     "shell.execute_reply.started": "2025-04-07T17:25:32.465006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def sharpen_image(image):\n",
    "#     kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  \n",
    "#     sharpened = cv2.filter2D(image, -1, kernel)\n",
    "#     return np.clip(sharpened, 0, 255).astype(np.uint8)\n",
    "\n",
    "# def augment_with_sharpening(df, output_dir):\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     augmented_data_sharp = []\n",
    "\n",
    "#     for _, row in df.iterrows():\n",
    "#         image_path, label = row[\"Image_Path\"], row[\"Label\"]\n",
    "\n",
    "#         image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#         if image is None:\n",
    "#             print(f\"Skipping unreadable file: {image_path}\")\n",
    "#             continue  # Skip corrupt images\n",
    "\n",
    "#         sharpened_image = sharpen_image(image)\n",
    "\n",
    "#         # This saves new sharpened image\n",
    "#         base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "#         new_filename = f\"{base_name}_sharpened.png\"\n",
    "#         new_path = os.path.join(output_dir, new_filename)\n",
    "#         cv2.imwrite(new_path, sharpened_image)\n",
    "\n",
    "#         # Stores new path & label\n",
    "#         augmented_data_sharp.append((new_path, label))\n",
    "\n",
    "#     return augmented_data_sharp\n",
    "\n",
    "# output_dir = \"/kaggle/working/sharpened_images\"\n",
    "# sharpened_list = augment_with_sharpening(df, output_dir)\n",
    "\n",
    "# augmented_df_sharp = pd.DataFrame(sharpened_list, columns=[\"Image_Path\", \"Label\"])\n",
    "# augmented_df_sharp.to_csv(\"sharpened_labels.csv\", index=False)\n",
    "\n",
    "# print(\"Sharpened images added.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining original, rotated and augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:33.107104Z",
     "iopub.status.busy": "2025-04-07T17:25:33.106829Z",
     "iopub.status.idle": "2025-04-07T17:25:33.141744Z",
     "shell.execute_reply": "2025-04-07T17:25:33.140901Z",
     "shell.execute_reply.started": "2025-04-07T17:25:33.107084Z"
    },
    "id": "Ao6_iyP6VXII",
    "outputId": "7df4f8d7-f29a-4deb-b6bf-91a83c07efdf",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in combined dataset: 17436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# combing all 3 dfs - original,rotated,gaussian_noise\n",
    "combined_df = pd.concat([df, rotated_df, augmented_df_noise], ignore_index=True)  # Resets index\n",
    "\n",
    "# Save the combined DataFrame\n",
    "combined_df.to_csv(\"combined_dataset.csv\", index=False)\n",
    "\n",
    "print(f\"Total images in combined dataset: {len(combined_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing image dimensions \n",
    "### Computing summary statistics and percentiles (90th to 99th) for width and height of all training images to determine the ideal padding dimensions for resizing while maintaining aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:35.791053Z",
     "iopub.status.busy": "2025-04-07T17:25:35.790740Z",
     "iopub.status.idle": "2025-04-07T17:25:38.372998Z",
     "shell.execute_reply": "2025-04-07T17:25:38.372173Z",
     "shell.execute_reply.started": "2025-04-07T17:25:35.791029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Height  Width\n",
      "0          39     25\n",
      "1         161    109\n",
      "2          19     59\n",
      "3          49      5\n",
      "4          12      9\n",
      "...       ...    ...\n",
      "17431      30     69\n",
      "17432      31     53\n",
      "17433      40     39\n",
      "17434      39    152\n",
      "17435      31    118\n",
      "\n",
      "[17436 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "    image_path = row[\"Image_Path\"]\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is not None:\n",
    "        h, w, _ = image.shape  # Get height and width\n",
    "        image_sizes.append([h, w])\n",
    "    else:\n",
    "        print(f\"Error loading image: {image_path}\")  # Handle missing/corrupt images\n",
    "\n",
    "# Create DataFrame from the list\n",
    "img_sizes_df = pd.DataFrame(image_sizes, columns=[\"Height\", \"Width\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(img_sizes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:38.374301Z",
     "iopub.status.busy": "2025-04-07T17:25:38.373972Z",
     "iopub.status.idle": "2025-04-07T17:25:38.400271Z",
     "shell.execute_reply": "2025-04-07T17:25:38.399480Z",
     "shell.execute_reply.started": "2025-04-07T17:25:38.374276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17436.000000</td>\n",
       "      <td>17436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.055288</td>\n",
       "      <td>74.917642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.732167</td>\n",
       "      <td>49.234420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>171.000000</td>\n",
       "      <td>280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Height         Width\n",
       "count  17436.000000  17436.000000\n",
       "mean      34.055288     74.917642\n",
       "std       11.732167     49.234420\n",
       "min        2.000000      1.000000\n",
       "25%       30.000000     36.000000\n",
       "50%       33.000000     63.000000\n",
       "75%       39.000000    110.000000\n",
       "max      171.000000    280.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_sizes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:38.401979Z",
     "iopub.status.busy": "2025-04-07T17:25:38.401757Z",
     "iopub.status.idle": "2025-04-07T17:25:38.413354Z",
     "shell.execute_reply": "2025-04-07T17:25:38.412652Z",
     "shell.execute_reply.started": "2025-04-07T17:25:38.401959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Width 90 percentile : 148.0\n",
      "Train Images Width 91 percentile : 152.0\n",
      "Train Images Width 92 percentile : 155.0\n",
      "Train Images Width 93 percentile : 158.0\n",
      "Train Images Width 94 percentile : 163.0\n",
      "Train Images Width 95 percentile : 168.0\n",
      "Train Images Width 96 percentile : 174.0\n",
      "Train Images Width 97 percentile : 179.95000000000073\n",
      "Train Images Width 98 percentile : 188.0\n",
      "Train Images Width 99 percentile : 200.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Train Images Width \"+str(90+i)+ \" percentile :\",np.percentile(img_sizes_df['Width'].values,90+i))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:38.414304Z",
     "iopub.status.busy": "2025-04-07T17:25:38.414095Z",
     "iopub.status.idle": "2025-04-07T17:25:38.432265Z",
     "shell.execute_reply": "2025-04-07T17:25:38.431391Z",
     "shell.execute_reply.started": "2025-04-07T17:25:38.414286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Height 90 percentile : 47.0\n",
      "Train Images Height 91 percentile : 48.0\n",
      "Train Images Height 92 percentile : 49.0\n",
      "Train Images Height 93 percentile : 49.0\n",
      "Train Images Height 94 percentile : 51.0\n",
      "Train Images Height 95 percentile : 52.0\n",
      "Train Images Height 96 percentile : 53.0\n",
      "Train Images Height 97 percentile : 55.0\n",
      "Train Images Height 98 percentile : 58.0\n",
      "Train Images Height 99 percentile : 65.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Train Images Height \"+str(90+i)+ \" percentile :\",np.percentile(img_sizes_df['Height'].values,90+i))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a taregt height and width for padding based on the above analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:47.464115Z",
     "iopub.status.busy": "2025-04-07T17:25:47.463784Z",
     "iopub.status.idle": "2025-04-07T17:25:47.467746Z",
     "shell.execute_reply": "2025-04-07T17:25:47.467005Z",
     "shell.execute_reply.started": "2025-04-07T17:25:47.464086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# BASED ON THIS 160(HEIGHT) AND 50(WIDTH) SEEM THE RIGHT CHOICES FOR SCALING\n",
    "target_h=50\n",
    "target_w=160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering all images and applying padding\n",
    "### Processes original, rotated and noised images\n",
    "### Resizing them while maintaining their aspect ratio and applying padding to match the target dimensions\n",
    "### The padded images are then converted to grayscale and saved in an output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:25:53.199252Z",
     "iopub.status.busy": "2025-04-07T17:25:53.198958Z",
     "iopub.status.idle": "2025-04-07T17:25:58.263358Z",
     "shell.execute_reply": "2025-04-07T17:25:58.262646Z",
     "shell.execute_reply.started": "2025-04-07T17:25:53.199230Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images collected: 16908\n",
      "Target dimensions decided based on analysis : h = 50, w = 160\n",
      "Saved: /kaggle/working/training_images/Don_52_with_noise.png\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=160x50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import typing\n",
    "\n",
    "# white as padding colour\n",
    "padding_color: typing.Tuple[int] = (255, 255, 255)\n",
    "\n",
    "input_dirs = [\"/kaggle/working/words_output\", \"/kaggle/working/rotated_images\", \"/kaggle/working/noisy_images\"]\n",
    "\n",
    "image_paths = []\n",
    "\n",
    "# Looping through each directory and collect image paths\n",
    "for input_dir in input_dirs:\n",
    "    if os.path.exists(input_dir): \n",
    "        images = [os.path.join(input_dir, img) for img in os.listdir(input_dir)\n",
    "                  if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        image_paths.extend(images)  \n",
    "    else:\n",
    "        print(f\"Warning: Directory {input_dir} does not exist.\")\n",
    "\n",
    "# number of images found\n",
    "print(f\"Total images collected: {len(image_paths)}\")\n",
    "\n",
    "print(f\"Target dimensions decided based on analysis : h = {target_h}, w = {target_w}\" )\n",
    "\n",
    "# Applying padding to each image\n",
    "output_dir = \"/kaggle/working/training_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Skipping {img_path}, could not load image.\")\n",
    "        continue\n",
    "\n",
    "    old_h, old_w = img.shape[:2]\n",
    "\n",
    "    # Resizing while maintaining aspect ratio\n",
    "    ratio = min(target_w / old_w, target_h / old_h)\n",
    "    new_w, new_h = int(old_w * ratio), int(old_h * ratio)\n",
    "    resized_image = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "    # Computing padding\n",
    "    delta_w = target_w - new_w\n",
    "    delta_h = target_h - new_h\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # Applying padding\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=padding_color)\n",
    "    \n",
    "    # Converting to grayscale and saving\n",
    "    gray_padded_image = cv2.cvtColor(padded_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, os.path.basename(img_path))\n",
    "    cv2.imwrite(output_path, gray_padded_image)\n",
    "\n",
    "print(f\"Saved: {output_path}\")\n",
    "\n",
    "# Showing an example\n",
    "cv2_imshow(gray_padded_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:05.288903Z",
     "iopub.status.busy": "2025-04-07T17:26:05.288601Z",
     "iopub.status.idle": "2025-04-07T17:26:05.323704Z",
     "shell.execute_reply": "2025-04-07T17:26:05.322975Z",
     "shell.execute_reply.started": "2025-04-07T17:26:05.288882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 4_179_with_noise.png, Shape: (50, 160)\n",
      "Image: conciencia_148_with_noise.png, Shape: (50, 160)\n",
      "Image: enten-_128_rotation_by_-5.png, Shape: (50, 160)\n",
      "Image: efte_78_rotation_by_-4.png, Shape: (50, 160)\n",
      "Image: no_139_rotation_by_3.png, Shape: (50, 160)\n",
      "Image: D._102_rotation_by_-2.png, Shape: (50, 160)\n",
      "Image: la_30_rotation_by_5.png, Shape: (50, 160)\n",
      "Image: prove-_72_rotation_by_3.png, Shape: (50, 160)\n",
      "Image: pues_36_rotation_by_-2.png, Shape: (50, 160)\n",
      "Image: Divi-_156_rotation_by_3.png, Shape: (50, 160)\n"
     ]
    }
   ],
   "source": [
    "# checking if padding has been applied correctly\n",
    "\n",
    "img_dir = \"/kaggle/working/training_images\"\n",
    "image_paths = [os.path.join(img_dir, img) for img in os.listdir(img_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Printing shape of 10 images\n",
    "for img_path in image_paths[:10]:\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) \n",
    "    if img is not None:\n",
    "        print(f\"Image: {os.path.basename(img_path)}, Shape: {img.shape}\")  # Printing filename and shape\n",
    "    else:\n",
    "        print(f\"Warning: Could not read {img_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding necessary parameters like max label length, total characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:08.875243Z",
     "iopub.status.busy": "2025-04-07T17:26:08.874936Z",
     "iopub.status.idle": "2025-04-07T17:26:08.887012Z",
     "shell.execute_reply": "2025-04-07T17:26:08.885982Z",
     "shell.execute_reply.started": "2025-04-07T17:26:08.875220Z"
    },
    "id": "Su3n2JFdFSWu",
    "outputId": "a62ab048-8afe-4986-f67a-5ce37079b89a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 91\n",
      "All Characters: \n",
      "{'B', 'u', '4', 'T', 'n', 'V', 'd', '+', '=', 's', 'q', '6', '{', '©', '0', '“', ':', 'Q', 'w', 'b', 'D', 'j', 'Z', 't', ';', 'e', '7', '*', '3', 'A', '-', 'O', '2', 'x', 'E', 'g', '_', 'Y', 'v', '8', 'H', '~', '.', 'y', 'p', 'R', ')', '<', 'M', '!', '\\\\', '\"', '@', 'F', 'h', '¥', '’', 'N', '«', 'J', 'o', '°', '¢', '1', 'G', 'f', '5', 'P', '(', 'c', 'a', '%', 'l', ',', '|', 'r', 'm', \"'\", 'é', '£', 'I', '9', 'L', 'S', 'C', 'U', '&', 'i', 'K', 'z', '‘'}\n"
     ]
    }
   ],
   "source": [
    "all_chars = set(ch for label in combined_df[\"Label\"] for ch in label)\n",
    "total_classes = len(all_chars)\n",
    "\n",
    "print(f\"Total characters: {total_classes}\")\n",
    "print(f\"All Characters: \\n{all_chars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:10.511578Z",
     "iopub.status.busy": "2025-04-07T17:26:10.511205Z",
     "iopub.status.idle": "2025-04-07T17:26:10.522637Z",
     "shell.execute_reply": "2025-04-07T17:26:10.521768Z",
     "shell.execute_reply.started": "2025-04-07T17:26:10.511547Z"
    },
    "id": "pttCFzTcFSPI",
    "outputId": "504a97c7-eeb4-48af-a4cb-9d848f4323ad",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max true label length: 16\n"
     ]
    }
   ],
   "source": [
    "max_label_length = max(combined_df[\"Label\"].apply(len))\n",
    "print(f\"Max true label length: {max_label_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:10.678885Z",
     "iopub.status.busy": "2025-04-07T17:26:10.678599Z",
     "iopub.status.idle": "2025-04-07T17:26:10.686761Z",
     "shell.execute_reply": "2025-04-07T17:26:10.685904Z",
     "shell.execute_reply.started": "2025-04-07T17:26:10.678864Z"
    },
    "id": "e8kqHqH3FSMM",
    "outputId": "15778792-0606-4fc4-8e4f-5945ccc6ed6a",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./words_output/x_4.png</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./words_output/+_5.png</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./words_output/\"3_6.png</td>\n",
       "      <td>\"3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./words_output/R_8.png</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./words_output/,_9.png</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Image_Path Label\n",
       "0   ./words_output/x_4.png     x\n",
       "1   ./words_output/+_5.png     +\n",
       "2  ./words_output/\"3_6.png    \"3\n",
       "3   ./words_output/R_8.png     R\n",
       "4   ./words_output/,_9.png     ,"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into 80% train,20% valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:12.545469Z",
     "iopub.status.busy": "2025-04-07T17:26:12.545138Z",
     "iopub.status.idle": "2025-04-07T17:26:13.125751Z",
     "shell.execute_reply": "2025-04-07T17:26:13.124864Z",
     "shell.execute_reply.started": "2025-04-07T17:26:12.545444Z"
    },
    "id": "9q3k_Br0Nnfg",
    "outputId": "38cb7bc2-efc6-4343-feeb-311e0b9fe92e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has been split\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"combined_dataset.csv\")\n",
    "\n",
    "train_csv, valid_csv = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "train_csv.to_csv(\"train.csv\", index=False)\n",
    "valid_csv.to_csv(\"valid.csv\", index=False)\n",
    "\n",
    "print(\"data has been split\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the mapping dictionaries for character to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:14.284159Z",
     "iopub.status.busy": "2025-04-07T17:26:14.283872Z",
     "iopub.status.idle": "2025-04-07T17:26:15.811779Z",
     "shell.execute_reply": "2025-04-07T17:26:15.810813Z",
     "shell.execute_reply.started": "2025-04-07T17:26:14.284137Z"
    },
    "id": "d2H8isCAQ6ah",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Character to number\n",
    "char_to_num = layers.StringLookup(vocabulary = list(all_chars),mask_token = None)\n",
    "\n",
    "# Reverse mapping\n",
    "num_to_char = layers.StringLookup(vocabulary = char_to_num.get_vocabulary(),mask_token = None,invert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:15.813204Z",
     "iopub.status.busy": "2025-04-07T17:26:15.812981Z",
     "iopub.status.idle": "2025-04-07T17:26:15.921662Z",
     "shell.execute_reply": "2025-04-07T17:26:15.921004Z",
     "shell.execute_reply.started": "2025-04-07T17:26:15.813185Z"
    },
    "id": "eRn6maTucoY5",
    "outputId": "7fe7a066-9dd9-458b-cc5c-c5f38f6c9b74",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping:\n",
      "'B': 1\n",
      "'u': 2\n",
      "'4': 3\n",
      "'T': 4\n",
      "'n': 5\n",
      "'V': 6\n",
      "'d': 7\n",
      "'+': 8\n",
      "'=': 9\n",
      "'s': 10\n",
      "'q': 11\n",
      "'6': 12\n",
      "'{': 13\n",
      "'©': 14\n",
      "'0': 15\n",
      "'“': 16\n",
      "':': 17\n",
      "'Q': 18\n",
      "'w': 19\n",
      "'b': 20\n",
      "'D': 21\n",
      "'j': 22\n",
      "'Z': 23\n",
      "'t': 24\n",
      "';': 25\n",
      "'e': 26\n",
      "'7': 27\n",
      "'*': 28\n",
      "'3': 29\n",
      "'A': 30\n",
      "'-': 31\n",
      "'O': 32\n",
      "'2': 33\n",
      "'x': 34\n",
      "'E': 35\n",
      "'g': 36\n",
      "'_': 37\n",
      "'Y': 38\n",
      "'v': 39\n",
      "'8': 40\n",
      "'H': 41\n",
      "'~': 42\n",
      "'.': 43\n",
      "'y': 44\n",
      "'p': 45\n",
      "'R': 46\n",
      "')': 47\n",
      "'<': 48\n",
      "'M': 49\n",
      "'!': 50\n",
      "'\\': 51\n",
      "'\"': 52\n",
      "'@': 53\n",
      "'F': 54\n",
      "'h': 55\n",
      "'¥': 56\n",
      "'’': 57\n",
      "'N': 58\n",
      "'«': 59\n",
      "'J': 60\n",
      "'o': 61\n",
      "'°': 62\n",
      "'¢': 63\n",
      "'1': 64\n",
      "'G': 65\n",
      "'f': 66\n",
      "'5': 67\n",
      "'P': 68\n",
      "'(': 69\n",
      "'c': 70\n",
      "'a': 71\n",
      "'%': 72\n",
      "'l': 73\n",
      "',': 74\n",
      "'|': 75\n",
      "'r': 76\n",
      "'m': 77\n",
      "''': 78\n",
      "'é': 79\n",
      "'£': 80\n",
      "'I': 81\n",
      "'9': 82\n",
      "'L': 83\n",
      "'S': 84\n",
      "'C': 85\n",
      "'U': 86\n",
      "'&': 87\n",
      "'i': 88\n",
      "'K': 89\n",
      "'z': 90\n",
      "'‘': 91\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping:\")\n",
    "for char in all_chars:\n",
    "    print(f\"'{char}': {char_to_num(tf.constant(char)).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting image to tensor \n",
    "\n",
    "#### Converts an image to a grayscale tensor, normalizes it, resizes it, and transposes its dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:16.431091Z",
     "iopub.status.busy": "2025-04-07T17:26:16.430779Z",
     "iopub.status.idle": "2025-04-07T17:26:16.435476Z",
     "shell.execute_reply": "2025-04-07T17:26:16.434799Z",
     "shell.execute_reply.started": "2025-04-07T17:26:16.431066Z"
    },
    "id": "4zdCGT7dRAxw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def image_to_tensor(image_path : str):\n",
    "   \n",
    "    image = tf.io.read_file(image_path)\n",
    "    decoded = tf.image.decode_jpeg(contents = image, channels = 1)\n",
    "    temp = tf.image.convert_image_dtype(image = decoded, dtype = tf.float32)\n",
    "    resized_image = tf.image.resize(images = temp, size = (target_h, target_w))\n",
    "    image = tf.transpose(resized_image, perm = [1, 0, 2])\n",
    "\n",
    "    # Converting image to a tensor.\n",
    "    image = tf.cast(image, dtype = tf.float32)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes each image \n",
    "\n",
    "#### Processes an image and its label by converting the image to a tensor, encoding the label as character indices, and padding it to a fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:16.907280Z",
     "iopub.status.busy": "2025-04-07T17:26:16.906987Z",
     "iopub.status.idle": "2025-04-07T17:26:16.912144Z",
     "shell.execute_reply": "2025-04-07T17:26:16.911128Z",
     "shell.execute_reply.started": "2025-04-07T17:26:16.907257Z"
    },
    "id": "qc5XVMBRR4H8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_sample(image_path : str, label : str):\n",
    "    # Getting the image\n",
    "    image = image_to_tensor(image_path)\n",
    "    # Converting label into char vectors\n",
    "    chars = tf.strings.unicode_split(label, input_encoding='UTF-8')\n",
    "    processed = char_to_num(chars)\n",
    "\n",
    "    # Padding to max label elngth using the unk character\n",
    "    padding_len = max_label_length - tf.shape(processed)[0]\n",
    "    processed = tf.pad(processed, paddings = [[0, padding_len]], constant_values=total_classes+3)\n",
    "\n",
    "    return {'image':image, 'label':processed}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts predictions to text\n",
    "#### Decodes model predictions into text by applying CTC decoding, converting numeric sequences to characters, joining them into words, and removing unknown tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:19.709293Z",
     "iopub.status.busy": "2025-04-07T17:26:19.708978Z",
     "iopub.status.idle": "2025-04-07T17:26:19.714073Z",
     "shell.execute_reply": "2025-04-07T17:26:19.713413Z",
     "shell.execute_reply.started": "2025-04-07T17:26:19.709270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_predictions_to_text(predictions):\n",
    "    seq_lengths = np.ones(shape=predictions.shape[0]) * predictions.shape[1]\n",
    "    decoded_output = keras.backend.ctc_decode(predictions, input_length=seq_lengths, greedy=True)[0][0][:, :max_label_length]\n",
    "\n",
    "    # numeric to char to word\n",
    "    char_sequences = num_to_char(decoded_output)\n",
    "    final_texts = [tf.strings.reduce_join(inputs=seq).numpy().decode('UTF-8') for seq in char_sequences]\n",
    "\n",
    "    # Removing unknown tokens\n",
    "    cleaned_texts = [text.replace('[UNK]', \" \").strip() for text in final_texts]\n",
    "\n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TensorFlow datasets for training and validation by shuffling, processing, batching, and prefetching image-label pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:24.947107Z",
     "iopub.status.busy": "2025-04-07T17:26:24.946813Z",
     "iopub.status.idle": "2025-04-07T17:26:25.424848Z",
     "shell.execute_reply": "2025-04-07T17:26:25.423927Z",
     "shell.execute_reply.started": "2025-04-07T17:26:24.947086Z"
    },
    "id": "zgu1FO1FSOws",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 8\n",
    "autotune = tf.data.AUTOTUNE\n",
    "train_size = len(train_csv)\n",
    "\n",
    "# Training data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((np.array(train_csv['Image_Path'].to_list()), np.array(train_csv['Label'].to_list()))\n",
    ").shuffle(train_size).map(process_sample, num_parallel_calls=autotune).batch(batch_size).prefetch(autotune)\n",
    "\n",
    "# Validation data\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((np.array(valid_csv['Image_Path'].to_list()), np.array(valid_csv['Label'].to_list()))\n",
    ").map(process_sample, num_parallel_calls=autotune).batch(batch_size).prefetch(autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:32.707112Z",
     "iopub.status.busy": "2025-04-07T17:26:32.706770Z",
     "iopub.status.idle": "2025-04-07T17:26:32.712189Z",
     "shell.execute_reply": "2025-04-07T17:26:32.711502Z",
     "shell.execute_reply.started": "2025-04-07T17:26:32.707083Z"
    },
    "id": "k-ymTOh6T4Hi",
    "outputId": "003e88c6-dc16-47a8-c066-0caa34fac666",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size : 13952\n",
      "validation Data Size : 3488\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Size : {tf.data.Dataset.cardinality(train_dataset).numpy() * batch_size}\")\n",
    "print(f\"validation Data Size : {tf.data.Dataset.cardinality(valid_dataset).numpy() * batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the CTC layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:35.605097Z",
     "iopub.status.busy": "2025-04-07T17:26:35.604802Z",
     "iopub.status.idle": "2025-04-07T17:26:35.610523Z",
     "shell.execute_reply": "2025-04-07T17:26:35.609581Z",
     "shell.execute_reply.started": "2025-04-07T17:26:35.605075Z"
    },
    "id": "a4g4aefDUSHT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "        input_len = tf.cast(tf.shape(y_pred)[1], dtype='int64') * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "        label_len = tf.cast(tf.shape(y_true)[1], dtype='int64') * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "        loss = self.loss_fn(y_true, y_pred, input_len, label_len)\n",
    "        self.add_loss(loss)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:39.767062Z",
     "iopub.status.busy": "2025-04-07T17:26:39.766779Z",
     "iopub.status.idle": "2025-04-07T17:26:41.858704Z",
     "shell.execute_reply": "2025-04-07T17:26:41.857603Z",
     "shell.execute_reply.started": "2025-04-07T17:26:39.767040Z"
    },
    "id": "ArbaesRYU-RB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CRNN MODEL\n",
    "final_width=target_w\n",
    "final_height=target_h\n",
    "# Input Layer\n",
    "input_images = layers.Input(shape=(final_width, final_height, 1), name=\"image\")\n",
    "\n",
    "# Labels : Added for the training.\n",
    "target_labels = layers.Input(shape=(None, ), name=\"label\")\n",
    "\n",
    "# CNN\n",
    "model = layers.Conv2D(filters=32,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')(input_images)\n",
    "model = layers.BatchNormalization()(model)\n",
    "model = layers.Conv2D(filters=32,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')(model)\n",
    "model = layers.BatchNormalization()(model)\n",
    "\n",
    "model = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(model)\n",
    "\n",
    "model = layers.Conv2D(filters=64,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')(model)\n",
    "model = layers.BatchNormalization()(model)\n",
    "model = layers.Conv2D(filters=128,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')(model)\n",
    "model = layers.BatchNormalization()(model)\n",
    "\n",
    "model = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(model)\n",
    "\n",
    "# CNN to RNN\n",
    "model = layers.Reshape(target_shape=((final_width//4), (final_height//4)*128))(model)\n",
    "model = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(model)\n",
    "model = layers.Dropout(0.5)(model)\n",
    "\n",
    "# RNN\n",
    "model = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.5))(model)\n",
    "model = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.5))(model)\n",
    "\n",
    "# Output Layer\n",
    "model = layers.Dense(len(char_to_num.get_vocabulary())+1, activation='softmax',name='dense_layer')(model)\n",
    "\n",
    "# CTC Layer\n",
    "ctc_layer = CTCLayer()(target_labels, model)\n",
    "\n",
    "# Model\n",
    "model_final = keras.Model(inputs=[input_images, target_labels],outputs=[ctc_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:26:42.241835Z",
     "iopub.status.busy": "2025-04-07T17:26:42.241547Z",
     "iopub.status.idle": "2025-04-07T17:26:42.273481Z",
     "shell.execute_reply": "2025-04-07T17:26:42.272829Z",
     "shell.execute_reply.started": "2025-04-07T17:26:42.241815Z"
    },
    "id": "Yu6qMdkP1ZDi",
    "outputId": "c0ea6f97-4aa7-495a-b83f-9a60548298e0",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,736</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ label (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">23,901</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ ctc_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CTCLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ label[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                           │                        │                │ dense_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │            \u001b[38;5;34m320\u001b[0m │ image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │            \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m9,248\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │            \u001b[38;5;34m128\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1536\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m196,736\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │        \u001b[38;5;34m788,480\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m656,384\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ label (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m93\u001b[0m)         │         \u001b[38;5;34m23,901\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ ctc_layer (\u001b[38;5;33mCTCLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m93\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ label[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                           │                        │                │ dense_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,768,445</span> (6.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,768,445\u001b[0m (6.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,767,933</span> (6.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,767,933\u001b[0m (6.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:27:07.522056Z",
     "iopub.status.busy": "2025-04-07T17:27:07.521760Z",
     "iopub.status.idle": "2025-04-07T17:27:07.534457Z",
     "shell.execute_reply": "2025-04-07T17:27:07.533754Z",
     "shell.execute_reply.started": "2025-04-07T17:27:07.522034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_final.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3))\n",
    "lr = callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3,verbose=1,min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T17:27:09.428961Z",
     "iopub.status.busy": "2025-04-07T17:27:09.428676Z",
     "iopub.status.idle": "2025-04-07T18:10:13.497436Z",
     "shell.execute_reply": "2025-04-07T18:10:13.496629Z",
     "shell.execute_reply.started": "2025-04-07T17:27:09.428940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 135.8913 - val_loss: 100.3511 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 86.0356 - val_loss: 40.5035 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 37.1793 - val_loss: 23.3787 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 30ms/step - loss: 24.7470 - val_loss: 19.5280 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 30ms/step - loss: 20.1311 - val_loss: 16.2743 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 16.5548 - val_loss: 13.7352 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 14.5391 - val_loss: 11.8206 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 13.1851 - val_loss: 12.0330 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 11.7949 - val_loss: 9.5636 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 10.7127 - val_loss: 10.2482 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 10.0590 - val_loss: 8.5075 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 9.4495 - val_loss: 7.5636 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 8.7487 - val_loss: 7.3161 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 8.6502 - val_loss: 7.3598 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 8.3056 - val_loss: 7.5058 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 8.1010 - val_loss: 6.4467 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 7.5006 - val_loss: 8.0830 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 6.9978 - val_loss: 6.2810 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 6.8481 - val_loss: 6.2810 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 6.9735 - val_loss: 5.8613 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 6.9121 - val_loss: 5.6763 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 6.3723 - val_loss: 5.2189 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 6.1585 - val_loss: 5.9426 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 6.4983 - val_loss: 4.8798 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 5.8061 - val_loss: 6.9857 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 6.0652 - val_loss: 6.9678 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m1743/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.6474\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 5.6474 - val_loss: 5.1588 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 30ms/step - loss: 4.7571 - val_loss: 3.5536 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 3.9543 - val_loss: 3.2022 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 3.9004 - val_loss: 3.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 3.6634 - val_loss: 3.1937 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 3.3092 - val_loss: 3.1269 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 30ms/step - loss: 3.3663 - val_loss: 2.7856 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 3.1566 - val_loss: 3.1282 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 3.1538 - val_loss: 2.8751 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.8996 - val_loss: 2.2246 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.8334 - val_loss: 2.6276 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.8203 - val_loss: 2.5189 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.7270 - val_loss: 2.1663 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 2.8541 - val_loss: 2.2927 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.5351 - val_loss: 2.2866 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m1743/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.6203\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.6204 - val_loss: 2.4827 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.5091 - val_loss: 1.9456 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 30ms/step - loss: 2.1441 - val_loss: 1.8981 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 1.9537 - val_loss: 1.9668 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 2.0137 - val_loss: 1.8082 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 1.9108 - val_loss: 1.9176 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 1.8128 - val_loss: 1.8331 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m1743/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6902\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 1.6902 - val_loss: 1.8531 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m1744/1744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 29ms/step - loss: 1.6636 - val_loss: 1.5849 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model_final.fit(train_dataset, validation_data=valid_dataset,epochs=50,callbacks=[callbacks.EarlyStopping(patience=5, restore_best_weights=True),lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:45:19.250715Z",
     "iopub.status.busy": "2025-04-07T19:45:19.250320Z",
     "iopub.status.idle": "2025-04-07T19:45:19.403342Z",
     "shell.execute_reply": "2025-04-07T19:45:19.402661Z",
     "shell.execute_reply.started": "2025-04-07T19:45:19.250686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_final.save('model_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making inference model from input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:35:43.596014Z",
     "iopub.status.busy": "2025-04-07T19:35:43.595649Z",
     "iopub.status.idle": "2025-04-07T19:35:43.602905Z",
     "shell.execute_reply": "2025-04-07T19:35:43.601780Z",
     "shell.execute_reply.started": "2025-04-07T19:35:43.595985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inference_model = keras.Model(\n",
    "    inputs=model_final.input,  # This refers to the actual input tensor\n",
    "    outputs=model_final.get_layer(name=\"dense_layer\").output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARING INFERENCE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:46:13.100903Z",
     "iopub.status.busy": "2025-04-07T19:46:13.100594Z",
     "iopub.status.idle": "2025-04-07T19:46:14.297388Z",
     "shell.execute_reply": "2025-04-07T19:46:14.296622Z",
     "shell.execute_reply.started": "2025-04-07T19:46:13.100881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preapred an inference df with image path and corresponding labels\n"
     ]
    }
   ],
   "source": [
    "# code for extracting images and padding is almost same as done above for preparing training data and can be done toegther with it \n",
    "# but have done here for clarity in code flow\n",
    "image_paths = [\"/kaggle/working/split_images/page_6_right.png\"]\n",
    "output_dir = \"./inf_words\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "word_data = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "  image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "  gray=image\n",
    "  # Perform OCR with bounding boxes\n",
    "  custom_config = r'--oem 3 --psm 6'  # OCR Engine 3, Page Segmentation Mode 6\n",
    "  data = pytesseract.image_to_data(gray, config=custom_config, output_type=Output.DICT)\n",
    "\n",
    "  # Process each word\n",
    "  for i in range(len(data['text'])):\n",
    "      text = data['text'][i].strip()\n",
    "      if text:\n",
    "          x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "\n",
    "          # Extracting word image\n",
    "          word_img = image[y:y+h, x:x+w]\n",
    "\n",
    "          # Saving image with text as filename\n",
    "          word_filename = f\"{output_dir}/{text}_{i}.png\"\n",
    "          cv2.imwrite(word_filename, word_img)\n",
    "\n",
    "          # Storing file path and label in list\n",
    "          word_data.append((word_filename, text))\n",
    "\n",
    "          # Drawing bounding boxes on the main image\n",
    "          cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "          cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "inf_df = pd.DataFrame(word_data, columns=[\"Image_Path\", \"Label\"])\n",
    "\n",
    "#cleaning the df to get rid of corrupted paths\n",
    "inf_df = inf_df[inf_df[\"Image_Path\"].apply(os.path.exists)]\n",
    "\n",
    "# Reseting index after filtering\n",
    "inf_df = inf_df.reset_index(drop=True)\n",
    "inf_df.to_csv(\"inf_words_labels.csv\", index=False)\n",
    "\n",
    "print(\"preapred an inference df with image path and corresponding labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:35:54.089859Z",
     "iopub.status.busy": "2025-04-07T19:35:54.089634Z",
     "iopub.status.idle": "2025-04-07T19:35:54.157794Z",
     "shell.execute_reply": "2025-04-07T19:35:54.157142Z",
     "shell.execute_reply.started": "2025-04-07T19:35:54.089840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images collected: 198\n",
      "Saved: /kaggle/working/inf_images/bacion._174.png\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAAAyCAAAAAD+Co+5AAANu0lEQVR4Ab1Z+3cbx3WemV28HwRBgBAZPiSBpkiJFGnKUuzIVqSkspsTOzlx2uOenv6Y9m/qL32cNj09aZq0cWSnqdVEthVLii1RkEiK74dIPEgAxBtY7O7M9N4FRUrWioJOfDwEFruzM3O/+e6de+8MqSR/UpFEEkrwc1AkJ4zu1eDw8KVUCqgkcMEOUkjC2EEPaCOk+vjz/j39kwFSKSU9ECYBGVRQAaBaUvAJUQIm+AGQrce9t9Cm1WAf0pM3tgA54woOZI38ZHvbJ5AKQiTK58gDZ09SatupzUpbgDhfnTgOaGlrMAkUcSaZYDA1ZOsrKXaK58radi7rnRh0c6q0KQUYJAIGo7xYd7jczq8KH7EDmL19+05ut+sHb8cdbcLDVSKYAmugcn+2qHYfHQsemFjbY9g2tAP4wX8tpw0jOXCuT30BIsD0hWDJf/28TGKnfnLK/RUhtAP4+epGk5BGGRdku6XlbJj5xe82TLJV+OGL9D1Uhh1FoyNdqlQcKgPH1W6hljek5dmMzmmzZsCK+WqKHYMXWaFWlsz5Jf/7HIHoW6R0RkVNOsPtrq3njAmv7QAOJSPgfIUpqeUKW1yAqwP5+94DVYgRAt0sagEZk1zxnSt/co+7+hRoDB0sDVi9cBB03vAHr1qawTb4ORSlHUCPT3BJhG71FY+MAAQKHJ1wylpxC3Ghh8YfSzCl7lc8RwbzXa8POvbhWa8sDAiSQBgkEANwIOz23GIHUDg5xE6c2aPptQazYhSOCpwgOcAENoCLlApcmCJZZOzYGxuh+IATWwBjiJ/C6gZYcIudBHZs4YIBMTgfWuwASgW9GHg1GNLknDqZNV2K4wumA4FUsWRY4BhIEwJdOmAkrCvaP+T2I7A9FPgDHRGWpMA+tMZnCDdQB1X46pBiB5CqAJDyeiFL6uWK7u+PuLEZsMpZubzTVJk7FPaAJAuCbBQ1vWo4I6EgClaE4tXrHksus9jCVAJbSpwKXHUB7pWaBnHANHHShxY7gMQLdib11HR+J1WsmbHJyaMRLxglJXp25s56laneoUsnPUgJfI3l6+lqQfcMnZnsBtoaZmVzJxbvaHHMa3WwZYfHQ71AFoVQXTB2qgPdrFTYbYS7/B5YTYfis13FNIyMya3fOlJ5sOng3MxrZ+I+WBjN4pVrt0qmJMqQjPSBTilvatnf/3xVaxK15+6bf+UhIpW+M78z+eejMCNJ6vnVteyu9PYPHYl5VSkbsnojvZj/zpvizuJacWD0xHDoOSZoC5AF+joqklbmpAFKkfV8MpV/6xQl1dXEv63k/J66LjZ+PRYBJcvGSmLuzlwJtNioJzNnj/m0O//zWdpMvTwK6hb67PX7yw+L0t07AmtnUEo9/eCfVzZJXdm+/iCrd8fPi7Hg4QTaApSmg1Gp+PsC0LmSKRnJXD7cG+bbt/7hNguc652/rxVvzUy4GDG3/++nM1wJBohZrTfWVzv85Zv/URdKzppZY/X9X6yb3pivvDH3q3E15mLOyr3f61wu/n0u0xRiI10NxQJgJYdp2dYGK7N5kzjH3pvy0ObdX39e4PrChzBbvjnv8A7/5LWfb2UIT+W7FKrPX1sxlfDUlLs4u2jGfT7pORKqU9eAE33P2s9+tW74xr8fX7t+s7b+/qlhp7ezLjihD2Vw0Nwtmvrq7AXwC5arfRZMW4CFogH5cc/IWIAaUbV+Q5DSynbdrRw5udPz1kTP1JmPy6B6WCLVlaROnSM/PBeoL90vx1/qpMFv3fzQ8Hc6gJfq7CfLRmj8ncvR072OT0uJa8E+2RF1G+CpTnxzvD738UNa3Cyj09r33DbqtgMomjq6BJ/fpQjn4HdzqWVAuDj+UuxVdnvkzSFTGQjWiA+ddXomaZLuV8+fcIrjZ42OMOPq+Hc+0sSgH1xw8taa7n35xxfi7kiAr8+mPznqiXaOD84SHn3rL4b4UiHFhSmEgv4LPNEz9GwHUI2GFJ2qChfgx9TgK7eXwZmUmmrH5MjZyDeaDxbv5kzWEVCYmU9WODn2xoBDskAAVi1VSaAffGigzy1pNpFhrvj5IQYr/JujyeLsf3suuIYnVmokFuvvpOSotwQeHl215R9fACDxOxSMtgpjAoJXTIW+FNyZJMGprd9k55fWwUK9IVU+TDxsMhEZgsCBMQFop8RogPOpbYXdpFIX3v7xfidYGfP1uYxlFjzRL07fnzHckM1yrgI56BxBr5CaPL4zfFzTdgxyQ0Ky0IrolEO2Ag/adjLe5dA3fvG76xoGemgCi3W1DPdGA6wcBeGfubPApZLRONvdqDClZ8BtZUCuCDj/leOZXu/pf2EOAVGUwbRhSrB7hIJR6QUYVPIc5Jk7eRNTF8XnBR24oiHDKKx++LPlo7HtDc6oqirUH3IB/OziQEiRJtOdEny3pwsSmbBDpXWYQ0PHoMsV4h10QspQBY/kdQmD8kbJZwJEmCXsUTEePWvfbptLNOdWTClq8ytVPA2olLhkzNPXF8pc/en760d+9NdnXEBvusClfzAIETC7kNEguEBOwbh0hPtA18FuhyyulZjTSUAXEBIlN4AhZ5MUE3XJcul0iasmOEuHAh0hexCVYu1xxR7c26lYJja4KkTxs1fB1bHcjXnIPBxBr/bpPya04KtDU+XPdCFKC0ZP14kwzDDzh17ncUqYkZaDYKwGmlZAlbUaLIBKBR4gfayuFCWjDq+kiS0qm1Xe4SzD2QdmW+gNapn87lDcVsl2ANVYZNOktHDzn0rnQrszv50mSvhMr8gm7hakNu3K5x0w6C/174d9/rBXk7U/NorvHK+sTCdcb5+OmNKUDgbGH44HM6K4U/cqUmr3biAO6TSFpptAj+qE0xtGBTdRPbsffLhYOnfpwskD4vbv7AAKF6QisC5THwTU3rUr90zF0RULKc26BrpK/qFU3IY1t33v2ypV3JAB0Opdo3Ky+fH9zYGToyKzLoi5sRpyxUaPbBmZ+WRIIdrCjbu7Unae6VENA8w7cgwcE6w+YHB3NRSp3fnPxI65u7D8d8P7uPZv7AAqWhX6Msq3P0p3b93OiMDo2bPHgztoRoKnimDl4Bc21hqh4MhL83Up6jOVG9WHed4dctJcCgAuJE86fPGL6RVt+lqkz8zd/CBLfOF33wnTxrwppSFgEVlpTDnHXEbmi3sZTqrzjck2AUKuCose8l5zcdOjVXjvhT873RsV6BqxsmFaB2nlbfC4387xVdgAaitJQzf8E8eC1Tuf6KS6+Bv3a119F6c3taUr6nlv4uqcDJ/61ntgZYWHsGrSa2tBlkqClMKDcXdx/lbWpIwbucTf7BO3f2PHoNk/2aHCnCq1RkOV0eHJy2c7HFRGjkWTQip8MrK7UIas3+cg3uHL3k+nK1LoulR7XvvLuPLw0yUB5zMf1cRF/8S7LJG+3VjxP7jVDL78o0sDbtCADu6vcivsoP87A2s/f3eip7K01aSQMcjawj6sgxs7gOwVz2atwpuFTFVQb3xibBiTNiV8fiuxbThGLwxvXrlRVbu6Ia8Pnes9NjiTKWnUP/L6xfN+0qQxg5bKO6tpnXW8eeSLm9OzSVIr+abevjwAvlxGjhZ2DLJ0PF++lZQKRH1Yyv5vJLMYJxXYiT9V7AAq0dcbNSZNrZHX1FBXKOTB7Jg4J4Jz85XOS/2dWYXMRabG/OCFQ/7Y8I2ZbFHtufR6v5+SgffCZiNZME/1uSg9Ehh95WqiBlYX+95b/aqEiNPxt0tLJV1GnMHYSK2UU3t6op6RYvN2gUnv5BtPwcOtlk2lqUKcAyukmqG4INuAJrDk4PQvt10NHPfS5trcdHRsrAtjICX1rVStqXQc63GBmmRl2dCqTRkZisHRmJTl9VQDVm7niUH07ozUKuu7jWxz6LR8kKpv3jUvvxvXK2tXf5lUvce/+71TT4OxBfh0MwQIARdEKQqYY1NLuSM+2AtDoQK3puDa8MATAgts1zB9ghNCqOTcFNCAqK79g7I6p8V6NMg1jecWzVNDLiLK81dSSs/LJ+JgpF8u7QJEGwEKINpa23duQK4DFRaF8APB1HrEqr0EGcmFeWGWgh4PHvYKHDCbsNWGroZGPQ5oIgszur+j3w0kP1XaBrgHxiIN0UJHkGntwa2EDtEgplbeZDWzMEEzeGhlVS3pMBvkGDzZ3mBSaRacAQo70INZ7ANtFyBmQwjAGhMecKiWYCuls4BCleU+raaPZLVAWK9aQi1grbfILA4D6bfA4GUH0G4VtwZ64gqd4Rm27jDI3qgId3/ElkDkBA3Raoz9sSl+4XpQ94g7qw/OGNl85ilNmwBbaFtycNIwJmBB6cgalta1BQntEQFZwvElkoS/WIBkZhky+i6shVfg9tEm7YoVEe1efKkOZwrTtI6IrDGZgqdF+EEpKAhFoIoxjONUWrWW/Cel47wsVuEdBHULPwQCe4xtMogCLcNrybWuLQZA1p44iw8GyRQ2RIYfkYYw9jQM5LWaQSYIN60hIZe05nPQ4zF2kJmvp6ClSR2jGRzCWardo+5w8e2q+PBR2nmLihUuQSHwWap9xO9z+n59DOIRNrfWjqVnolibpX07eBbONm3wWd1foB5Wai1F6g7Y9DkgNnZ0OtHmbO3u8VG/PoCwAZm9ek2Tl7xab2DHODkV3XNTj8N5+v7rA0iY9sd/T1f4lktCGFfG/a1/pjzPFP8fSGj39pt8ph4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=160x50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "padding_color: typing.Tuple[int] = (255, 255, 255)\n",
    "input_dirs = [\"/kaggle/working/inf_words\"]\n",
    "image_paths = []\n",
    "\n",
    "for input_dir in input_dirs:\n",
    "    if os.path.exists(input_dir): \n",
    "        images = [os.path.join(input_dir, img) for img in os.listdir(input_dir)\n",
    "                  if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        image_paths.extend(images) \n",
    "    else:\n",
    "        print(f\"Warning: Directory {input_dir} does not exist.\")\n",
    "\n",
    "print(f\"Total images collected: {len(image_paths)}\")\n",
    "\n",
    "\n",
    "# Applying padding to each image\n",
    "output_dir = \"/kaggle/working/inf_images\" \n",
    "os.makedirs(output_dir, exist_ok=True) \n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Skipping {img_path}, could not load image.\")\n",
    "        continue\n",
    "\n",
    "    old_h, old_w = img.shape[:2]\n",
    "\n",
    "    # Resizing while maintaining aspect ratio\n",
    "    ratio = min(target_w / old_w, target_h / old_h)\n",
    "    new_w, new_h = int(old_w * ratio), int(old_h * ratio)\n",
    "    resized_image = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "    # computing padding\n",
    "    delta_w = target_w - new_w\n",
    "    delta_h = target_h - new_h\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # Applying padding\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=padding_color)\n",
    "    \n",
    "    gray_padded_image = cv2.cvtColor(padded_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, os.path.basename(img_path))\n",
    "    cv2.imwrite(output_path, gray_padded_image)\n",
    "\n",
    "print(f\"Saved: {output_path}\")\n",
    "#exampple image\n",
    "cv2_imshow(gray_padded_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:35:58.945388Z",
     "iopub.status.busy": "2025-04-07T19:35:58.945052Z",
     "iopub.status.idle": "2025-04-07T19:35:59.013373Z",
     "shell.execute_reply": "2025-04-07T19:35:59.012748Z",
     "shell.execute_reply.started": "2025-04-07T19:35:58.945358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inf_dataset = tf.data.Dataset.from_tensor_slices((np.array(inf_df['Image_Path'].to_list()), np.array(inf_df['Label'].to_list()))\n",
    ").map(process_sample, num_parallel_calls=autotune).batch(batch_size).prefetch(autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:35:59.294939Z",
     "iopub.status.busy": "2025-04-07T19:35:59.294672Z",
     "iopub.status.idle": "2025-04-07T19:35:59.299324Z",
     "shell.execute_reply": "2025-04-07T19:35:59.298548Z",
     "shell.execute_reply.started": "2025-04-07T19:35:59.294915Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference data Size : 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"inference data Size : {tf.data.Dataset.cardinality(inf_dataset).numpy() * batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:01.350229Z",
     "iopub.status.busy": "2025-04-07T19:36:01.349943Z",
     "iopub.status.idle": "2025-04-07T19:36:02.910537Z",
     "shell.execute_reply": "2025-04-07T19:36:02.909629Z",
     "shell.execute_reply.started": "2025-04-07T19:36:01.350207Z"
    },
    "id": "gDNck0wba3jd",
    "outputId": "df2bff49-be5f-4d23-9d89-9c59d97cc374",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = convert_predictions_to_text(inference_model.predict(inf_dataset))\n",
    "true = inf_df['Label'].tolist()   #convert to test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying each true label vs predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:07.190145Z",
     "iopub.status.busy": "2025-04-07T19:36:07.189860Z",
     "iopub.status.idle": "2025-04-07T19:36:07.579460Z",
     "shell.execute_reply": "2025-04-07T19:36:07.578773Z",
     "shell.execute_reply.started": "2025-04-07T19:36:07.190124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "True -> Predicted\n",
      "-----------------\n",
      "MOTIVO -> OrNO\n",
      "DEL -> DEL\n",
      "AUTHOR, -> PTTIOI\n",
      "Y -> Y\n",
      "RAZON -> AAgos\n",
      "‘de -> e\n",
      "la -> la\n",
      "Obra. -> Gbra.\n",
      "A -> A.\n",
      "devocion -> devocion\n",
      ", -> ,\n",
      "y -> y\n",
      "afe&to, -> afeto,\n",
      "que -> que\n",
      "defde -> defde\n",
      "mis -> mis\n",
      "L -> .\n",
      "tiernos -> tiernos\n",
      "ahos -> afios\n",
      "profefse -> profefse\n",
      "4 -> 4\n",
      "la -> la\n",
      "Sagrada -> Sagrada\n",
      "Religion -> Religion\n",
      "de -> de\n",
      "la -> la\n",
      "Compafia -> Compatiia\n",
      "de -> de\n",
      "Jesus, -> Jesvs,\n",
      "y -> y\n",
      "la -> la\n",
      "profeflaré -> profeflare\n",
      "eternamente -> eermamente\n",
      ", -> ,\n",
      "como -> como\n",
      "hijo -> hijo\n",
      "el -> el\n",
      "mas -> mas\n",
      "reconocido -> reconocido\n",
      "a -> 4\n",
      "tan -> tan\n",
      "efcogida -> efcogida\n",
      "Madre -> Madre\n",
      ": -> :\n",
      "me -> ‘e\n",
      "obligo -> obligo\n",
      "a -> 4\n",
      "efcrivir -> efcrivir\n",
      ", -> ,\n",
      "y -> y\n",
      "dar -> dar\n",
      "ala -> ala\n",
      "Eftampa -> Eftampa\n",
      "efta -> efta\n",
      "Inftruccion -> Inftruccion\n",
      "para -> Para\n",
      "fus -> fus\n",
      "Sefores -> Sefiores\n",
      "Colegiales, -> Colegiales,\n",
      "fin -> fin\n",
      "que -> que\n",
      "por -> por\n",
      "effo -> efo\n",
      "fe -> fe\n",
      "niegue -> niegue\n",
      "a -> 4\n",
      "fervir -> fervir\n",
      "a -> 4\n",
      "los -> los\n",
      "de- -> de.\n",
      "mas -> mas\n",
      "Séfioritos -> Senoritos\n",
      ", -> ,\n",
      "que -> que\n",
      "nolo -> nolo\n",
      "fueren. -> fueren.\n",
      "Yaun- -> Vaun-\n",
      "que -> que\n",
      "la -> la\n",
      "Compafia -> Compaiia\n",
      ", -> ,\n",
      "mas -> mas\n",
      "por -> por\n",
      "fu -> fu\n",
      "conocida -> conocida\n",
      "atencion -> atencion\n",
      ", -> ,\n",
      "que -> que\n",
      "por -> or\n",
      "el -> el\n",
      "merito -> merito\n",
      ", -> ,\n",
      "que -> que\n",
      "yo -> yo\n",
      "no -> no\n",
      "tengo -> tengo\n",
      ", -> ,\n",
      "recibira -> recibira\n",
      "con -> con\n",
      "gufto -> gufto\n",
      "efte -> efte\n",
      "mi -> ni\n",
      "obfe- -> obfe-\n",
      "quio; -> quio\n",
      "todavia -> todavia\n",
      ", -> ,\n",
      "por -> por\n",
      "dirigirfe -> dirigirfe\n",
      "al -> al\n",
      "cultivo -> cultivo\n",
      "de -> de\n",
      "aquellas -> aquellas\n",
      "Plantas -> Plantas\n",
      ", -> ,\n",
      "que -> que\n",
      "la -> la\n",
      "Divina -> Divina\n",
      "Pro- -> Pro-\n",
      "videncia, -> videncia,\n",
      "por -> por\n",
      "medio -> medio\n",
      "del -> del\n",
      "Gran -> Gran\n",
      "Patriarca -> Batriarca\n",
      "Icnacio, -> lonacio\n",
      "fid -> ,o\n",
      "al -> al\n",
      "cuydado -> cundado\n",
      "zelofo -> zelofo\n",
      "de. -> de\n",
      "fu -> fu\n",
      "de- -> de.\n",
      "licada -> licada\n",
      "mano -> mano\n",
      ": -> :\n",
      "sé -> se\n",
      "yo -> yo\n",
      ",y -> ,y\n",
      "lo -> lo\n",
      "sé -> s¢\n",
      "muy -> muy\n",
      "bien, -> bien,\n",
      "que -> que\n",
      "le -> le\n",
      "merecera -> merecera\n",
      "efta -> efta\n",
      "Obritala -> Obritala\n",
      "primera -> primera\n",
      "apros -> apros\n",
      "bacion. -> bacion.\n",
      "; -> -\n",
      "Juzgo -> Juzgo\n",
      ", -> ,\n",
      "que -> que\n",
      "nadie -> nadie\n",
      "ignora -> ignora\n",
      ", -> ,\n",
      "quanto -> quanto\n",
      "trabaja -> trabaia\n",
      "la -> la\n",
      "Compaiia -> Compaiia\n",
      "en -> en\n",
      "la -> la\n",
      "crianza -> crianza\n",
      "de -> de\n",
      "los -> los\n",
      "nifios -> nifios\n",
      "en -> en\n",
      "fus -> fus\n",
      "Colegios -> Colegios\n",
      "(tarea -> taréa\n",
      "igualmente -> igualmente\n",
      "penofa, -> penofa,\n",
      "que -> que\n",
      "provechofa -> provechofa‘\n",
      ") -> )\n",
      "para -> para\n",
      "guardar? -> guardard\n",
      "les -> les\n",
      "del -> del\n",
      "mal, -> mal,\n",
      "é -> e\n",
      "inftruirles -> inftruirles\n",
      "en -> en\n",
      "el-bien -> elbien\n",
      "; -> ;\n",
      "y -> y\n",
      "que -> que\n",
      "por -> por\n",
      "effo -> effo\n",
      "les -> les\n",
      "enfena -> enfeia\n",
      "las -> las\n",
      "buenas -> buenas\n",
      "aes -> s\n",
      "para -> para\n",
      "“ -> |\n",
      "inior- -> ntor-\n"
     ]
    }
   ],
   "source": [
    "predictions = convert_predictions_to_text(inference_model.predict(inf_dataset))\n",
    "print(\"True -> Predicted\")\n",
    "print(\"-----------------\")\n",
    "for true_label, pred_label in zip(inf_df[\"Label\"], predictions):\n",
    "    print(f\"{true_label} -> {pred_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CTC Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:08.120195Z",
     "iopub.status.busy": "2025-04-07T19:36:08.119933Z",
     "iopub.status.idle": "2025-04-07T19:36:08.604846Z",
     "shell.execute_reply": "2025-04-07T19:36:08.604042Z",
     "shell.execute_reply.started": "2025-04-07T19:36:08.120174Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10,6))\n",
    "plt.legend(fontsize=15)\n",
    "plt.title(\"Learning Curve\", fontsize=15)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"CTC Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character error rate \n",
    "#### Word error rate\n",
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:10.175439Z",
     "iopub.status.busy": "2025-04-07T19:36:10.175094Z",
     "iopub.status.idle": "2025-04-07T19:36:10.210209Z",
     "shell.execute_reply": "2025-04-07T19:36:10.209489Z",
     "shell.execute_reply.started": "2025-04-07T19:36:10.175391Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 23.737 %\n",
      "Character Error Rate (CER): 8.434 %\n",
      "Accuracy: 76.26 %\n"
     ]
    }
   ],
   "source": [
    "from jiwer import cer,wer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_cer_jiwer(predictions_list, true_list):\n",
    "    return cer(true_list, predictions_list)\n",
    "\n",
    "def calculate_wer_jiwer(predictions_list, true_list):\n",
    "    return wer(true_list, predictions_list)\n",
    "\n",
    "def calculate_accuracy_jiwer(predictions_list, true_list):\n",
    "    return accuracy_score(true_list, predictions_list)\n",
    "\n",
    "# Calculate CER and Accuracy\n",
    "wer_value = calculate_wer_jiwer(predictions, true)\n",
    "cer_value = calculate_cer_jiwer(predictions, true)\n",
    "accuracy_value = calculate_accuracy_jiwer(predictions, true)\n",
    "\n",
    "print(f\"Word Error Rate (WER): {wer_value * 100:.3f} %\")\n",
    "print(f\"Character Error Rate (CER): {cer_value * 100:.3f} %\")\n",
    "print(f\"Accuracy: {accuracy_value * 100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving accuracy using constrained beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the custom lexicon from a collection of renaissance spanish words. These words were collected from different transcriptions and stored in a docx file initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:14.460328Z",
     "iopub.status.busy": "2025-04-07T19:36:14.460019Z",
     "iopub.status.idle": "2025-04-07T19:36:14.905006Z",
     "shell.execute_reply": "2025-04-07T19:36:14.904142Z",
     "shell.execute_reply.started": "2025-04-07T19:36:14.460305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon saved with 3747 unique words.\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "\n",
    "def extract_words(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    full_text = \" \".join([para.text for para in doc.paragraphs])  \n",
    "    words = full_text.split() \n",
    "    words = [word.strip(\",.?!;:()[]{}'\\\"\").lower() for word in words]  \n",
    "    return set(words)  \n",
    "\n",
    "docx_path = \"/kaggle/input/lexicon-spanish/lexicon_big.docx\"\n",
    "custom_lexicon = extract_words(docx_path)\n",
    "\n",
    "with open(\"custom_lexicon.txt\", \"w\") as f:\n",
    "    for word in sorted(custom_lexicon):\n",
    "        f.write(word + \"\\n\")\n",
    "\n",
    "print(f\"Lexicon saved with {len(custom_lexicon)} unique words.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:21.625267Z",
     "iopub.status.busy": "2025-04-07T19:36:21.624943Z",
     "iopub.status.idle": "2025-04-07T19:36:27.960887Z",
     "shell.execute_reply": "2025-04-07T19:36:27.959998Z",
     "shell.execute_reply.started": "2025-04-07T19:36:21.625240Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pybktree\n",
      "  Downloading pybktree-1.1.tar.gz (4.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n",
      "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pybktree\n",
      "  Building wheel for pybktree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pybktree: filename=pybktree-1.1-py3-none-any.whl size=4948 sha256=b7356b7183a288236aded2d8bd8723d6a46436ba0c5e302a23d7504fd52985f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/97/f5/14ae07459879c2738cfa34f61a8d3d2d99b13e15328bc6d1dc\n",
      "Successfully built pybktree\n",
      "Installing collected packages: pybktree, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.27.1 pybktree-1.1 python-Levenshtein-0.27.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pybktree python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying contrained beam search on predicted labels and lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:32.305803Z",
     "iopub.status.busy": "2025-04-07T19:36:32.305474Z",
     "iopub.status.idle": "2025-04-07T19:36:32.402320Z",
     "shell.execute_reply": "2025-04-07T19:36:32.401477Z",
     "shell.execute_reply.started": "2025-04-07T19:36:32.305777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: OrNO  →  Corrected: OrNO\n",
      "Predicted: DEL  →  Corrected: DEL\n",
      "Predicted: PTTIOI  →  Corrected: PTTIOI\n",
      "Predicted: Y  →  Corrected: Y\n",
      "Predicted: AAgos  →  Corrected: rigos\n",
      "Predicted: e  →  Corrected: e\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: Gbra.  →  Corrected: bran\n",
      "Predicted: A.  →  Corrected: \n",
      "Predicted: devocion  →  Corrected: devocion\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: y  →  Corrected: y\n",
      "Predicted: afeto,  →  Corrected: afectos\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: defde  →  Corrected: defde\n",
      "Predicted: mis  →  Corrected: mis\n",
      "Predicted: .  →  Corrected: \n",
      "Predicted: tiernos  →  Corrected: tiernos\n",
      "Predicted: afios  →  Corrected: ambos\n",
      "Predicted: profefse  →  Corrected: profefse\n",
      "Predicted: 4  →  Corrected: 4\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: Sagrada  →  Corrected: Sagrada\n",
      "Predicted: Religion  →  Corrected: Religion\n",
      "Predicted: de  →  Corrected: de\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: Compatiia  →  Corrected: Compatiia\n",
      "Predicted: de  →  Corrected: de\n",
      "Predicted: Jesvs,  →  Corrected: iesvs\n",
      "Predicted: y  →  Corrected: y\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: profeflare  →  Corrected: profeflare\n",
      "Predicted: eermamente  →  Corrected: eternamente\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: como  →  Corrected: como\n",
      "Predicted: hijo  →  Corrected: hijo\n",
      "Predicted: el  →  Corrected: el\n",
      "Predicted: mas  →  Corrected: mas\n",
      "Predicted: reconocido  →  Corrected: reconocido\n",
      "Predicted: 4  →  Corrected: \n",
      "Predicted: tan  →  Corrected: tan\n",
      "Predicted: efcogida  →  Corrected: efcogida\n",
      "Predicted: Madre  →  Corrected: Madre\n",
      "Predicted: :  →  Corrected: :\n",
      "Predicted: ‘e  →  Corrected: ze\n",
      "Predicted: obligo  →  Corrected: obligo\n",
      "Predicted: 4  →  Corrected: \n",
      "Predicted: efcrivir  →  Corrected: efcrivir\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: y  →  Corrected: y\n",
      "Predicted: dar  →  Corrected: dar\n",
      "Predicted: ala  →  Corrected: ala\n",
      "Predicted: Eftampa  →  Corrected: Eftampa\n",
      "Predicted: efta  →  Corrected: efta\n",
      "Predicted: Inftruccion  →  Corrected: Inftruccion\n",
      "Predicted: Para  →  Corrected: vara\n",
      "Predicted: fus  →  Corrected: fus\n",
      "Predicted: Sefiores  →  Corrected: Sefiores\n",
      "Predicted: Colegiales,  →  Corrected: Colegiales,\n",
      "Predicted: fin  →  Corrected: fin\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: por  →  Corrected: por\n",
      "Predicted: efo  →  Corrected: so\n",
      "Predicted: fe  →  Corrected: fe\n",
      "Predicted: niegue  →  Corrected: niegue\n",
      "Predicted: 4  →  Corrected: \n",
      "Predicted: fervir  →  Corrected: fervir\n",
      "Predicted: 4  →  Corrected: \n",
      "Predicted: los  →  Corrected: los\n",
      "Predicted: de.  →  Corrected: de-\n",
      "Predicted: mas  →  Corrected: mas\n",
      "Predicted: Senoritos  →  Corrected: señoritos\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: nolo  →  Corrected: nolo\n",
      "Predicted: fueren.  →  Corrected: fueren.\n",
      "Predicted: Vaun-  →  Corrected: jun-\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: Compaiia  →  Corrected: compañia\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: mas  →  Corrected: mas\n",
      "Predicted: por  →  Corrected: por\n",
      "Predicted: fu  →  Corrected: fu\n",
      "Predicted: conocida  →  Corrected: conocida\n",
      "Predicted: atencion  →  Corrected: atencion\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: or  →  Corrected: oc\n",
      "Predicted: el  →  Corrected: el\n",
      "Predicted: merito  →  Corrected: merito\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: yo  →  Corrected: yo\n",
      "Predicted: no  →  Corrected: no\n",
      "Predicted: tengo  →  Corrected: tengo\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: recibira  →  Corrected: recibira\n",
      "Predicted: con  →  Corrected: con\n",
      "Predicted: gufto  →  Corrected: gufto\n",
      "Predicted: efte  →  Corrected: efte\n",
      "Predicted: ni  →  Corrected: ni\n",
      "Predicted: obfe-  →  Corrected: obfe-\n",
      "Predicted: quio  →  Corrected: quiso\n",
      "Predicted: todavia  →  Corrected: todavia\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: por  →  Corrected: por\n",
      "Predicted: dirigirfe  →  Corrected: dirigirfe\n",
      "Predicted: al  →  Corrected: al\n",
      "Predicted: cultivo  →  Corrected: cultivo\n",
      "Predicted: de  →  Corrected: de\n",
      "Predicted: aquellas  →  Corrected: aquellas\n",
      "Predicted: Plantas  →  Corrected: Plantas\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: Divina  →  Corrected: Divina\n",
      "Predicted: Pro-  →  Corrected: Pro-\n",
      "Predicted: videncia,  →  Corrected: videncia,\n",
      "Predicted: por  →  Corrected: por\n",
      "Predicted: medio  →  Corrected: medio\n",
      "Predicted: del  →  Corrected: del\n",
      "Predicted: Gran  →  Corrected: Gran\n",
      "Predicted: Batriarca  →  Corrected: patriarca\n",
      "Predicted: lonacio  →  Corrected: lonio\n",
      "Predicted: ,o  →  Corrected: so\n",
      "Predicted: al  →  Corrected: al\n",
      "Predicted: cundado  →  Corrected: cuydado\n",
      "Predicted: zelofo  →  Corrected: zelofo\n",
      "Predicted: de  →  Corrected: de\n",
      "Predicted: fu  →  Corrected: fu\n",
      "Predicted: de.  →  Corrected: de-\n",
      "Predicted: licada  →  Corrected: licada\n",
      "Predicted: mano  →  Corrected: mano\n",
      "Predicted: :  →  Corrected: :\n",
      "Predicted: se  →  Corrected: se\n",
      "Predicted: yo  →  Corrected: yo\n",
      "Predicted: ,y  →  Corrected: ,y\n",
      "Predicted: lo  →  Corrected: lo\n",
      "Predicted: s¢  →  Corrected: so\n",
      "Predicted: muy  →  Corrected: muy\n",
      "Predicted: bien,  →  Corrected: bien,\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: le  →  Corrected: le\n",
      "Predicted: merecera  →  Corrected: merecera\n",
      "Predicted: efta  →  Corrected: efta\n",
      "Predicted: Obritala  →  Corrected: Obritala\n",
      "Predicted: primera  →  Corrected: primera\n",
      "Predicted: apros  →  Corrected: apros\n",
      "Predicted: bacion.  →  Corrected: bacion.\n",
      "Predicted: -  →  Corrected: \n",
      "Predicted: Juzgo  →  Corrected: Juzgo\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: nadie  →  Corrected: nadie\n",
      "Predicted: ignora  →  Corrected: ignora\n",
      "Predicted: ,  →  Corrected: ,\n",
      "Predicted: quanto  →  Corrected: quanto\n",
      "Predicted: trabaia  →  Corrected: trabajo\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: Compaiia  →  Corrected: Compaiia\n",
      "Predicted: en  →  Corrected: en\n",
      "Predicted: la  →  Corrected: la\n",
      "Predicted: crianza  →  Corrected: crianza\n",
      "Predicted: de  →  Corrected: de\n",
      "Predicted: los  →  Corrected: los\n",
      "Predicted: nifios  →  Corrected: nifios\n",
      "Predicted: en  →  Corrected: en\n",
      "Predicted: fus  →  Corrected: fus\n",
      "Predicted: Colegios  →  Corrected: Colegios\n",
      "Predicted: taréa  →  Corrected: tarea\n",
      "Predicted: igualmente  →  Corrected: igualmente\n",
      "Predicted: penofa,  →  Corrected: penofa,\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: provechofa‘  →  Corrected: provechofa‘\n",
      "Predicted: )  →  Corrected: )\n",
      "Predicted: para  →  Corrected: para\n",
      "Predicted: guardard  →  Corrected: guarda\n",
      "Predicted: les  →  Corrected: les\n",
      "Predicted: del  →  Corrected: del\n",
      "Predicted: mal,  →  Corrected: mal,\n",
      "Predicted: e  →  Corrected: e\n",
      "Predicted: inftruirles  →  Corrected: inftruirles\n",
      "Predicted: en  →  Corrected: en\n",
      "Predicted: elbien  →  Corrected: bien\n",
      "Predicted: ;  →  Corrected: ;\n",
      "Predicted: y  →  Corrected: y\n",
      "Predicted: que  →  Corrected: que\n",
      "Predicted: por  →  Corrected: por\n",
      "Predicted: effo  →  Corrected: effo\n",
      "Predicted: les  →  Corrected: les\n",
      "Predicted: enfeia  →  Corrected: enseña\n",
      "Predicted: las  →  Corrected: las\n",
      "Predicted: buenas  →  Corrected: buenas\n",
      "Predicted: s  →  Corrected: s\n",
      "Predicted: para  →  Corrected: para\n",
      "Predicted: |  →  Corrected: \n",
      "Predicted: ntor-  →  Corrected: anto-\n"
     ]
    }
   ],
   "source": [
    "import pybktree\n",
    "import Levenshtein\n",
    "\n",
    "def levenshtein_distance(a, b):\n",
    "    return Levenshtein.distance(a, b)\n",
    "\n",
    "def build_bk_tree(lexicon):\n",
    "    return pybktree.BKTree(levenshtein_distance, lexicon)\n",
    "\n",
    "def constrained_beam_search(predicted_labels, true_labels, bk_tree, max_edit_distance=2):\n",
    "    #Performs constrained beam search by replacing predicted words with the closest words from the lexicon using Levenshtein distance.\n",
    "    corrected_predictions = []\n",
    "    \n",
    "    for pred_word, true_word in zip(predicted_labels, true_labels):\n",
    "        # If prediction is already correct, I keep it\n",
    "        if pred_word == true_word:\n",
    "            corrected_predictions.append(pred_word)\n",
    "            continue\n",
    "\n",
    "        # Search for closest words in lexicon within max_edit_distance\n",
    "        candidates = bk_tree.find(pred_word, max_edit_distance)\n",
    "        \n",
    "        if candidates:\n",
    "            # Select the closest word (with the smallest edit distance)\n",
    "            best_match = min(candidates, key=lambda x: x[0])[1]\n",
    "            corrected_predictions.append(best_match)\n",
    "        else:\n",
    "            # If no close match found,I keep original prediction\n",
    "            corrected_predictions.append(pred_word)\n",
    "    \n",
    "    return corrected_predictions\n",
    "\n",
    "# storing our custom lexicon as the lexicon\n",
    "lexicon = custom_lexicon\n",
    "\n",
    "# building BK-tree from the lexicon\n",
    "bk_tree = build_bk_tree(lexicon)\n",
    "\n",
    "# predicted and true Labels\n",
    "predicted_labels = predictions\n",
    "true_labels = true\n",
    "\n",
    "# performing Constrained Beam Search\n",
    "corrected_predictions = constrained_beam_search(predicted_labels, true_labels, bk_tree, max_edit_distance=2)\n",
    "\n",
    "# results\n",
    "for pred, corrected in zip(predicted_labels, corrected_predictions):\n",
    "    print(f\"Predicted: {pred}  →  Corrected: {corrected}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final metrics after constrained beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:36:50.505264Z",
     "iopub.status.busy": "2025-04-07T19:36:50.504956Z",
     "iopub.status.idle": "2025-04-07T19:36:50.516153Z",
     "shell.execute_reply": "2025-04-07T19:36:50.515492Z",
     "shell.execute_reply.started": "2025-04-07T19:36:50.505243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 21.717 %\n",
      "Character Error Rate (CER): 10.000 %\n",
      "Accuracy: 78.28 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate CER and Accuracy after applying constrained beam search decoding\n",
    "wer_value = calculate_wer_jiwer(corrected_predictions, true)\n",
    "cer_value = calculate_cer_jiwer(corrected_predictions, true)\n",
    "accuracy_value = calculate_accuracy_jiwer(corrected_predictions, true)\n",
    "\n",
    "print(f\"Word Error Rate (WER): {wer_value * 100:.3f} %\")\n",
    "print(f\"Character Error Rate (CER): {cer_value * 100:.3f} %\")\n",
    "print(f\"Accuracy: {accuracy_value * 100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6946236,
     "sourceId": 11136706,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6955731,
     "sourceId": 11149229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6956229,
     "sourceId": 11149916,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7076465,
     "sourceId": 11313752,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7076497,
     "sourceId": 11313789,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
